scrapy框架

-- 什么是框架
    - 集成了很多功能的,并且具有很强通用性的一个项目模板.

-- 如何学习框架
    - 专门学习框架封装各种功能的详细用法.

-- 什么是scrapy?
    - 爬虫中封装好的一个明星框架.功能: 高性能的持久化操作,异步的数据下载,高性能的数据解析,分布式

- scrapy框架的基本使用
    - 环境的安装
        - mac&liunx  pip install scrapy
        - windows:  ancandow
            pip install wheel
            下载Twisted 安装
            pip install pywin32
            conda install scrapy

    - 创建一个工程: scrapy startproject xxxPro
     - cd xxxPro
    - 需要在spiders子目录中创建一个爬虫文件
        - scrapy genspider spidername www.xxx.com

    - 执行工程
        - scrapy crawl spidername


- 数据解析
    content = div.xpath('./a[1]/div/span[1]//text()').extract()
- 持久化存储
    - 基于终端指令:
        - 要求: 只可以将parse方法的返回值存储到本地的文本文件
        - 注意; 持久化存储对应的文本文件类型只可以为 json csv pickle xml
        - 指令:  scrapy crawl xxx -o filePath      -o 存储路径
        - 好处: 简单,便捷
        - 缺点: 局限性比较强(数据只可以存储到指定后缀的文本文件)

    - 基于管道:
        - 编码流程:
            - 数据解析
            - 在item类中定义相关的属性
            - 将解析的数据封装储存到item类型的对象
            - 将item对象提交给管道进行持久化储存的操作
            - 在管道类的process_item中要将其接收受到的item对象中储存的数据进行持久化存储操作
            - 需要在配置文件中开启管道

        - 好处:
            - 通用性强.
        - 面试题: 将爬取到的数据一份存储到本地一份存储到数据库.如何实现?
            - 管道文件中的一个管道类对应是将数据存储到一种平台
            - 爬虫文件调交的item只会给管道文件中第一个被执行的管道类接收
            - precess_item中的 return item 表示将item传递给下一个即将被执行的管道类